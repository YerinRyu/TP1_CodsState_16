{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuriCha02/TP1_CodsState_16/blob/main/AnnModel3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFzL-PCdJU8-"
      },
      "outputs": [],
      "source": [
        "%run /content/AnnModel1.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@차지형\n",
        "\n",
        "**설명**\n",
        "\n",
        "`AnnModel1.ipynb`파일내부에 method를 사용할수 있게, 실행함"
      ],
      "metadata": {
        "id": "h2Siw3p0F5SM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msTkqcMMJeoP"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def multiple_load_dataset():\n",
        "    with open('.../mulit_classification_data.csv') as csvfile:\n",
        "        csvreader = csv.reader(csvfile)\n",
        "        next(csvreader)\n",
        "        rows = []\n",
        "        for row in csvreader:\n",
        "            rows.append(row)\n",
        "\n",
        "    global data, input_cnt, output_cnt\n",
        "\n",
        "    input_cnt, output_cnt = 27, 7\n",
        "    data = np.asarray(rows, dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@차지형\n",
        "\n",
        "**Multiple_load_dataset()에 결과 값**\n",
        "\n",
        "data, input_cnt, output_cnt를 글로벌 변수값으로 저장해서, 다른 변수에서 사용이 가능함.\n",
        "- 대신 변수 이름이 겹칠 가능성이 높음.\n",
        "  - 특히 고객들이 코드를 편집해서 사용해야 할 경우\n",
        "\n",
        "`data`:\n",
        "\n",
        "- 행:\n",
        "> ```\n",
        "[ 4.20000e+01  5.00000e+01  2.70900e+05  2.70944e+05  2.67000e+02\n",
        "  1.70000e+01  4.40000e+01  2.42200e+04  7.60000e+01  1.08000e+02\n",
        "  1.68700e+03  1.00000e+00  0.00000e+00  8.00000e+01  4.98000e-02\n",
        "  2.41500e-01  1.81800e-01  4.70000e-03  4.70600e-01  1.00000e+00\n",
        "  1.00000e+00  2.42650e+00  9.03100e-01  1.64350e+00  8.18200e-01\n",
        " -2.91300e-01  5.82200e-01  1.00000e+00  0.00000e+00  0.00000e+00\n",
        "  0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00]\n",
        "```\n",
        "- 열 길이: 34\n",
        "- 행 길이: 1941"
      ],
      "metadata": {
        "id": "t6llJCIq7DYV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Koe2owaJcNY"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def multiple_main(epoch_count = 10, mb_size = 10, report=1, train_ratio = 0.6):\n",
        "    multiple_load_dataset()\n",
        "    init_param()\n",
        "    train_and_test(epoch_count,mb_size,report,train_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@차지형\n",
        "\n",
        "**설명**\n",
        "\n",
        "- `ANNModel1.ipynb`에서 `init_param()`과 `train_and_test()`을 불러옴\n",
        "- `multiple_load_dataset()`로 데이터를 불러와,\n",
        " - `data`, `input_cnt`, `output_cnt` 글로벌 변수를 출력함\n",
        "  - `input_cnt`, `output_cnt`는 AnnModel1에서 가져온 메서드 `init_param()`에 사용됨"
      ],
      "metadata": {
        "id": "OqRfToc0Fclc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkQXypCdJoQc"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def softmax(x):\n",
        "\n",
        "    max_elem = np.max(x, axis = 1)\n",
        "\n",
        "    diff = (x.transpose() - max_elem).transpose()\n",
        "    exp = np.exp(diff)\n",
        "\n",
        "    sum_exp = np.sum(exp, axis = 1)\n",
        "\n",
        "    probs = (exp.transpose()/sum_exp).transpose()\n",
        "\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@차지형\n",
        "\n",
        "**코드 설명:**\n",
        "\n",
        "`max_elem = np.max(x, axis = 1)`: 각 행에서 최대 값을 구하여, `max_elem`에 저장함\n",
        "\n",
        "`diff = (x.transpose() - max_elem).transpose()`: 각 행의 모든 값과 그 행의 차이를 구하여 `diff`에 저장함.\n",
        "- 아마 다름 `np.exp()`에서 negative 값을 positive 값으로 바꿀떄,값들 사이에 차이가 너무 벌어지지 않도록 차이를 구하서 거리를 좁히는 것 같음\n",
        "\n",
        "`exp = np.exp(diff)`: negative 값을 positve값으로 변경하여 `exp`로 저장함\n",
        "\n",
        "`sum_exp = np.sum(exp, axis = 1)`: 각 행에서 값들을 모두 더해서 `sum_exp`에 저장함\n",
        "\n",
        "`probs = (exp.transpose()/sum_exp).transpose()`: `exp`에서 'sum_exp'를 나누어 확률을 구함\n",
        "\n",
        "`return probs`: 확률을 function 외부로 배출함\n",
        "\n",
        "**추가**: pytorch를 사용할 경우, `transpose()`를 일일히 사용할 필요 없이, 내부에서 알아서 해줌."
      ],
      "metadata": {
        "id": "gOXdybx-8hOs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCuGFYtWJj8K"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def softmax_cross_entropy(y_real, y_hat):\n",
        "\n",
        "    probs = softmax(y_hat)\n",
        "\n",
        "    #기존 확률값에 아주 작은 양수를 더해 log함수의 폭주 방지\n",
        "    return - np.sum(y_real * np.log(probs+1.0e-10), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@차지형\n",
        "\n",
        "**설명**\n",
        "\n",
        "`y_real`: test 확률\n",
        "\n",
        "`y_hat`: 예측확률\n",
        "\n",
        "\n",
        "`probs = softmax(y_hat)`예측확률을 softmax 확률로 변경하여 `probs`에 저장함\n",
        "\n",
        "`return - np.sum(y_real * np.log(probs+1.0e-10), axis=1)`: 각 행 (or 배치)에서 cross-entropy loss 값을 구함"
      ],
      "metadata": {
        "id": "ZL9FqWrjBXR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBzu6Z5DJrug"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def forward_postproc(y_hat, y_real):\n",
        "    entropy  = softmax_cross_entropy(y_real, y_hat)\n",
        "    loss     = np.mean(entropy)\n",
        "\n",
        "    return loss, [y_real, y_hat, entropy]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@차지형\n",
        "\n",
        "**설명**\n",
        "\n",
        "`entropy  = softmax_cross_entropy(y_real, y_hat)`: 예측값과 테스트 값을 비교하여 cross_entropy loss 값을 구하여 `entropy`로 저장함\n",
        "\n",
        "`loss = np.mean(entropy)`: `entropy`의 평균 값을 구함\n",
        "\n",
        "`return loss, [y_real, y_hat, entropy]`:\n",
        "- 평균 loss 점수을 출력함\n",
        "- 실제값과 예측값, 그리고 cross-entropy loss 값을 리스트로 출력함"
      ],
      "metadata": {
        "id": "psm9iw_CDiKJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5Lr3TOgJtxd"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def softmax_cross_entropy_with_derv(y_real,y_hat):\n",
        "\n",
        "    return softmax(y_hat) - y_real"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@차지형\n",
        "\n",
        "**설명**\n",
        "\n",
        "`return softmax(y_hat) - y_real`: 예측값의 softmax 확율과 실제값의 차이로 기울기를 구해 외부로 출력함."
      ],
      "metadata": {
        "id": "y60UVQetFA_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv-4uAgGJkn5"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def backprop_postproc(aux_pp):\n",
        "    y_real, y_hat, entropy = aux_pp\n",
        "\n",
        "    g_loss_entropy = 1.0/np.prod(entropy.shape)\n",
        "    g_entropy_output = softmax_cross_entropy_with_derv(y_real,y_hat)\n",
        "\n",
        "    G_output = g_entropy_output * g_loss_entropy\n",
        "\n",
        "    return G_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@차지형\n",
        "\n",
        "**설명**\n",
        "\n",
        "`aux_pp`: 위에 `forward_postproc` 메소드에서 출력한 `[y_real, y_hat, entropy]` 값임\n",
        "\n",
        "`y_real, y_hat, entropy = aux_pp`: 리스트를 다시 각각 나눔.\n",
        "\n",
        "`g_loss_entropy = 1.0/np.prod(entropy.shape)`: cross_entropy loss 값을 normalization 함\n",
        "- 예측값에 맞추어 모델의 기울기를 조절해주기 위해 만든 변수라고 생각함.\n",
        "\n",
        "`g_entropy_output = softmax_cross_entropy_with_derv(y_real,y_hat)`: 위에 정의된 `softmax_cross_entropy_with_derv` 메소드를 사용하여 모델의 기울기를 `g_entropy_output`라는 변수에 저장함.\n",
        "\n",
        "`G_output = g_entropy_output * g_loss_entropy`: 모델의 예측에 대한 손실의 기울기를 계산함\n",
        "\n",
        "`return G_output`: 모델의 손실 기울기를 외부로 출력함.\n",
        "\n"
      ],
      "metadata": {
        "id": "uHpN3cOXHIM7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ty-DSGNNJ2kO"
      },
      "outputs": [],
      "source": [
        "# 메서드 정의\n",
        "def eval_accuracy(y_hat,y_real):\n",
        "    estimate = np.argmax(y_hat,axis=1)\n",
        "    answer = np.argmax(y_real,axis=1)\n",
        "\n",
        "    correct = np.equal(estimate, answer)\n",
        "\n",
        "    return np.mean(correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@ 차지형\n",
        "\n",
        "**설명**\n",
        "\n",
        "`estimate = np.argmax(y_hat,axis=1)`: 예측확률 중에서 가장 가능성이 높은 레벨을 선택하여 `estimate`라는 변수에 저장함\n",
        "\n",
        "`answer = np.argmax(y_real,axis=1)`: 실제확률 중에서 가장 가능성이 높은 레벨을 선택하여 `answer`라는 변수에 저장함\n",
        "\n",
        "`correct = np.equal(estimate, answer)`: `estimate`과 `answer`를 비교하여, 값이 같으면 `True`를, 다른면 `False`를 `correct`라는 변수에 저장합니다.\n",
        "\n",
        "`return np.mean(correct)`: `correct`내의 `True`를 기준으로 평균을 외부로 출력합니다."
      ],
      "metadata": {
        "id": "C_idpM8yosoZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}